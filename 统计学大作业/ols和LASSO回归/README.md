模型部分应该没什么好说的，作为最小二乘优化的一种，LASSO回归相比起ols多了正则化（L1范数），比起岭回归收敛得更快，因此是业界常用的回归模型。模型的衡量选了常规的r2和mse。  
  
ols和LASSO回归的r2分别为0.66400和0.66283；mse分别为64.1400327724635和64.36227856727926。在得分上LASSO略逊色于ols,但这是正则化所致。模型拟合的效果在接受范围内，但是如果能加入更多因子，它应该还有提升空间。  
  
系数：  
ols:  
[-0.6726491   0.37756355 -0.06927305 -0.03379305  2.4496092   3.66373003
  2.51453995  3.3061683   4.97517851 -0.05989008 -0.86877649  0.02660885] 25.35262797453302  
  
LASSO:  
[-0.46927623  0.242233   -0.          0.          2.39197425  3.63802884
  2.47360064  3.2260643   4.93972587 -0.         -0.8009569  -0.        ] 25.82452502095839  
    
模型结果表明第5~第9个因子（即个人特质方面的所有因子）对模型产生了较大的正面影响，而来自外部的因素（学校的因素，最后三个因子）对模型的影响不大甚至会产生负面影响。这点与使用XGBoost的出来的结果不太一致（参考‘决策树与XGBoost’下面的‘因子重要性’两张图）  
  
未解之谜：  
真正吊诡的是在使用sklearn的accuracy_score对模型进行评分时，会报错说数据是连续性数据。而且用pred和target_test画图时，会发现target_test的曲线十分怪异。
